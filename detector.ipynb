{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.feature_bagging import FeatureBagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "df = pd.read_csv(\"public/data_source/rca.csv\")\n",
    "actualData = pd.read_csv(\"public/data_source/ret_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrix(actual, predicted):\n",
    "    confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "    cm_display.plot()\n",
    "    plt.show()\n",
    "    #print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.plot.scatter('latency', 'timestamp','source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['source'])\n",
    "LabelEncoder()\n",
    "list(le.classes_)\n",
    "sourceTransformed = le.transform(df['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df['latency'].values.reshape(-1,1)\n",
    "X2 = sourceTransformed.reshape(-1,1)\n",
    "\n",
    "X = np.concatenate((X1,X2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.1\n",
    "# Test 4 different methods\n",
    "classifiers = {\n",
    "        'FeatureBagging': FeatureBagging(contamination=outliers_fraction),\n",
    "        'KNN': KNN(contamination=outliers_fraction),\n",
    "        'HBOS': HBOS(contamination=outliers_fraction),\n",
    "        'IForest': IForest(contamination=outliers_fraction)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.linspace(-10, 10, 200), np.linspace(-10, 10, 200))\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    clf.fit(X)\n",
    "    # predict raw anomaly score\n",
    "    scores_pred = clf.decision_function(X) * -1\n",
    "\n",
    "    # prediction of a datapoint category outlier or inlier\n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    np.unique(y_pred, return_counts=True)\n",
    "\n",
    "    n_inliers = len(y_pred) - np.count_nonzero(y_pred)\n",
    "    n_outliers = np.count_nonzero(y_pred == 1)\n",
    "\n",
    "    print('\\n\\nOUTLIERS : ', n_outliers, 'INLIERS : ', n_inliers, clf_name)\n",
    "\n",
    "    outliers = []\n",
    "    for index in range(len(y_pred)):        \n",
    "        if y_pred[index] == 1:\n",
    "            outliers.append(index)\n",
    "\n",
    "    # print(outliers)\n",
    "\n",
    "    outliersList = df.iloc[outliers, :]\n",
    "    print(outliersList.head(10))\n",
    "\n",
    "    #getConfusionMatrix(y_pred)\n",
    "\n",
    "    #pd.DataFrame(outliersList).to_csv(\"public/results/\"+clf_name+\"_preresult.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    # threshold value to consider a datapoint inlier or outlier - the probability that the prediction is true\n",
    "#    threshold = stats.scoreatpercentile(scores_pred, 100 * outliers_fraction)\n",
    "\n",
    "    # decision function calculates the raw anomaly score for every point\n",
    "#    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()]) * -1\n",
    "#    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # plot outliers and contour\n",
    "#    subplot = plt .subplot(2, 2, i + 1)\n",
    "#    subplot.contour(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 15))\n",
    "#    subplot.contour(xx, yy, Z, levels=[threshold], linewidths=2, colors='red')\n",
    "\n",
    "    # fill orange contour lines where range of anomaly score is from threshold to maximum anomaly score\n",
    "#    subplot.contour(xx, yy, Z, levels=[threshold, Z.max()], colors='blue')\n",
    "\n",
    "    # scatter plot of inliers with white dots\n",
    "#    subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1],c='white', s=12, edgecolor='g')\n",
    "    # scatter plot of outliers with black dots\n",
    "#    subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1],c='black', s=12, edgecolor='g')\n",
    "#    subplot.axis('tight')\n",
    "\n",
    "#    subplot.set_title(clf_name)\n",
    "#    subplot.set_xlim((-15, 15))\n",
    "#    subplot.set_ylim((-15, 15))\n",
    "\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "actual = np.random.binomial(1,.9,size = 1000)\n",
    "predicted = np.random.binomial(1,.9,size = 1000)\n",
    "\n",
    "print(\"\\n\\nactual\\n\",actual)\n",
    "print(\"\\n\\npredicted\\n\",predicted)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eae90893e53faf00c1fb715e5fd3628d38903204ae2ebf0b6242386918c5bebf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
