{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.feature_bagging import FeatureBagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "df = pd.read_csv(\"public/data_source/rca_2020_04_24.csv\")\n",
    "faultsDataFrame = pd.read_csv(\"public/data_source/ret_info24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['source'])\n",
    "LabelEncoder()\n",
    "list(le.classes_)\n",
    "sourceTransformed = le.transform(df['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df['latency'].values.reshape(-1,1)\n",
    "X2 = sourceTransformed.reshape(-1,1)\n",
    "\n",
    "X = np.concatenate((X1,X2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.1\n",
    "# Test 4 different methods\n",
    "classifiers = {\n",
    "        #'FeatureBagging': FeatureBagging(contamination=outliers_fraction),\n",
    "        'KNN': KNN(contamination=outliers_fraction),\n",
    "        'HBOS': HBOS(contamination=outliers_fraction),\n",
    "        #'IForest': IForest(contamination=outliers_fraction)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetricsConfusionMatrix(faults, predicted):\n",
    "    confusion_matrix = metrics.confusion_matrix(faults, predicted)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "    cm_display.plot()\n",
    "    plt.show()\n",
    "    del confusion_matrix, cm_display    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrix(faults, predicted):\n",
    "    \n",
    "    truePositive = []\n",
    "    trueNegative = []\n",
    "    falsePositive = []\n",
    "    falseNegative = []\n",
    "    predicted = predicted.assign(date_time = list(map( lambda x: datetime.fromtimestamp(x/1000), predicted.timestamp)))\n",
    "    #predicted = predicted.assign(date_time = datetime.fromtimestamp((predicted.timestamp)/1000))\n",
    "    \n",
    "    for i, act in faults.iterrows():        \n",
    "        minTime = datetime.strptime(act.time_preliminary,'%Y-%m-%d %H:%M:%S+08:00')\n",
    "        maxTime = minTime + timedelta(minutes=5)\n",
    "\n",
    "        truePositive.append(predicted.loc[(predicted.date_time > minTime) & (predicted.date_time < maxTime) | (predicted.predition == 1) & (predicted.target == act.ground_truth)])\n",
    "        trueNegative.append(predicted.loc[(predicted.date_time > minTime) & (predicted.date_time < maxTime) | (predicted.predition == 0) & (predicted.target == act.ground_truth)])\n",
    "        falsePositive.append(predicted.loc[(predicted.date_time < minTime) | (predicted.date_time > maxTime) & (predicted.predition == 1)])\n",
    "        falseNegative.append(predicted.loc[(predicted.date_time < minTime) | (predicted.date_time > maxTime) & (predicted.predition == 0)])\n",
    "\n",
    "        del maxTime, minTime\n",
    "    \n",
    "    else: #remove all empty row\n",
    "        truePositive = list(filter(lambda dfTP: not dfTP.empty, truePositive))        \n",
    "        trueNegative = list(filter(lambda dfTN: not dfTN.empty, trueNegative))\n",
    "        falsePositive = list(filter(lambda dfFP: not dfFP.empty, falsePositive))\n",
    "        falseNegative = list(filter(lambda dfFN: not dfFN.empty, falseNegative))\n",
    "\n",
    "        count = 0\n",
    "        for i, *trueP in truePositive:\n",
    "             count = count + len(trueP)\n",
    "        print(\"True Positive: \", count)\n",
    "\n",
    "        count = 0\n",
    "        for i, *trueN in trueNegative:\n",
    "             count = count + len(trueN)\n",
    "        print(\"True Negative: \", count)\n",
    "\n",
    "        count = 0\n",
    "        for i, *falseP in falsePositive:\n",
    "             count = count + len(falseP)\n",
    "        print(\"False Positive: \", count)\n",
    "\n",
    "        count = 0\n",
    "        for i, *falseN in falseNegative:\n",
    "             count = count + len(falseN)\n",
    "        print(\"False Negative: \", count)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # print(\"\\nTrue Positive: \", len(truePositive))\n",
    "        # print(\"True Negative: \", len(trueNegative))\n",
    "        # print(\"False Positive: \", len(falsePositive))\n",
    "        # print(\"False Negative: \", len(falseNegative))\n",
    "        # print((falseNegative))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaultsData:     fault_id           time_preliminary duration ground_truth\n",
      "0        43  2020-05-20 19:40:00+08:00     5min       os_022\n",
      "1        44  2020-05-20 19:40:00+08:00     5min       os_022\n",
      "2        45  2020-05-20 19:40:00+08:00     5min   docker_001\n",
      "3        46  2020-05-20 19:40:00+08:00     5min   docker_001\n",
      "4        47  2020-05-20 19:40:00+08:00     5min   docker_001\n",
      "5        48  2020-04-24 05:17:00+08:00     5min   docker_002\n"
     ]
    }
   ],
   "source": [
    "print(\"FaultsData: \", faultsDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "OUTLIERS :  2004 INLIERS :  197996 KNN\n",
      "                 trace_id     timestamp  latency  succ      source      target\n",
      "55   c8c8c171a5313e154968  1.590000e+12      232  True      os_021  docker_004\n",
      "61   321fa171a5313e154064  1.590000e+12      179  True  docker_001  docker_007\n",
      "113  321fa171a5313e154064  1.590000e+12     1230  True      os_022  docker_001\n",
      "119  e151f171a5313e166714  1.590000e+12      182  True  docker_001  docker_007\n",
      "138  e151f171a5313e166714  1.590000e+12      183  True  docker_001  docker_007\n",
      "True Positive:  42\n",
      "True Negative:  42\n",
      "False Positive:  7\n",
      "False Negative:  7\n",
      "\n",
      "\n",
      "OUTLIERS :  11 INLIERS :  199989 HBOS\n",
      "                   trace_id     timestamp  latency  succ      source  \\\n",
      "2379   9fa77171a53144456718  1.590000e+12     2638  True        None   \n",
      "36245  2f62c171a531b7e64532  1.590000e+12     2806  True  docker_001   \n",
      "36468  65de4171a531b8f27324  1.590000e+12     3003  True  docker_001   \n",
      "36950  3c255171a531ba2c7330  1.590000e+12     2904  True  docker_001   \n",
      "37747  dbac0171a531bc7e7196  1.590000e+12     2907  True  docker_001   \n",
      "\n",
      "           target  \n",
      "2379       os_022  \n",
      "36245  docker_001  \n",
      "36468  docker_001  \n",
      "36950  docker_001  \n",
      "37747  docker_001  \n",
      "True Positive:  35\n",
      "True Negative:  42\n",
      "False Positive:  7\n",
      "False Negative:  7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx, yy = np.meshgrid(np.linspace(-10, 10, 200), np.linspace(-10, 10, 200))\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    clf.fit(X)\n",
    "    \n",
    "    scores_pred = clf.decision_function(X) * -1\n",
    "\n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    np.unique(y_pred, return_counts=True)\n",
    "\n",
    "    n_inliers = len(y_pred) - np.count_nonzero(y_pred)\n",
    "    n_outliers = np.count_nonzero(y_pred == 1)   \n",
    "\n",
    "    outliers = np.where(y_pred == 1)    \n",
    "    outliersList = df.iloc[outliers[0], :]\n",
    "\n",
    "    print('\\n\\nOUTLIERS : ', n_outliers, 'INLIERS : ', n_inliers, clf_name)\n",
    "    print(outliersList.head(5))\n",
    "\n",
    "    # expected = faultsDataFrame\n",
    "    # predicted = y_pred\n",
    "    # results = confusion_matrix(expected, predicted)\n",
    "    # print(results)\n",
    "    \n",
    "    predicted = df.assign(predition = y_pred)\n",
    "    getConfusionMatrix(faultsDataFrame, predicted)\n",
    "\n",
    "    #pd.DataFrame(outliersList).to_csv(\"public/results/\"+clf_name+\"_preresult.csv\")\n",
    "\n",
    "    # threshold value to consider a datapoint inlier or outlier - the probability that the prediction is true\n",
    "#    threshold = stats.scoreatpercentile(scores_pred, 100 * outliers_fraction)\n",
    "\n",
    "    # decision function calculates the raw anomaly score for every point\n",
    "#    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()]) * -1\n",
    "#    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # plot outliers and contour\n",
    "#    subplot = plt .subplot(2, 2, i + 1)\n",
    "#    subplot.contour(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 15))\n",
    "#    subplot.contour(xx, yy, Z, levels=[threshold], linewidths=2, colors='red')\n",
    "\n",
    "    # fill orange contour lines where range of anomaly score is from threshold to maximum anomaly score\n",
    "#    subplot.contour(xx, yy, Z, levels=[threshold, Z.max()], colors='blue')\n",
    "\n",
    "    # scatter plot of inliers with white dots\n",
    "#    subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1],c='white', s=12, edgecolor='g')\n",
    "    # scatter plot of outliers with black dots\n",
    "#    subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1],c='black', s=12, edgecolor='g')\n",
    "#    subplot.axis('tight')\n",
    "\n",
    "#    subplot.set_title(clf_name)\n",
    "#    subplot.set_xlim((-15, 15))\n",
    "#    subplot.set_ylim((-15, 15))\n",
    "\n",
    "#plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eae90893e53faf00c1fb715e5fd3628d38903204ae2ebf0b6242386918c5bebf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
